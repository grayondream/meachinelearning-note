# 1. 类别不平衡问题
## 1.1 简介
&emsp;&emsp;类别不均衡是指在分类学习算法中，不同类别样本的比例相差悬殊，它会对算法的学习过程造成重大的干扰。

## 1.2 解决办法
- 欠采样，减少数量较多那一类样本的数量，使得正负样本比例均衡。
- 过采样，增加数量较少那一类样本的数量，使得正负样本比例均衡。
- 不处理样本，样本分类阈值移动。

# 2. 解决办法
## 2.1 欠采样
### 2.1.1 随机欠采样
&emsp;&emsp;随机欠采样是指随机从多数类样本中抽取一部分数据进行删除，随机欠采样有一个很大的缺点是未考虑样本的分布情况，而采样过程又具有很大的随机性，可能会误删多数类样本中一些重要的信息。

### 2.1.2 EasyEnsemable
&emsp;&emsp;EasyEnsemble是通过多次从多数类样本有放回的随机抽取一部分样本生成多个子数据集，将每个子集与少数类数据联合起来进行训练生成多个模型，然后集合多个模型的结果进行判断。这种方法看起来和随机森林的原理很相似。

### 2.1.3 BalanceCascade
&emsp;&emsp;BalanceCascade是通过一次随机欠采样产生训练集，训练一个分类器，对于那些分类正确的多数类样本不放回，然后对这个剩下的多数类样本再次进行欠采样产生第二个训练集，训练第二个分类器，同样把分类正确的样本不放回，以此类推，直到满足某个停止条件，最终的模型也是多个分类器的组合。

### 2.1.4 基于knn欠采样
- NearMiss-1 :选择到最近的三个少数类样本平均距离最小的那些多数类样本;
- NearMiss-2 :选择到最远的三个少数类样本平均距离最小的那些多数类样本;
- NearMiss-3 :为每个少数类样本选择给定数目的最近多数类样本，目的是保证每个少数类样本都被一些多数类样本包围;
- 最远距离 :选择到最近的三个少数类样本平均距离最大的那些多数类样本。

## 2.2 过采样
### 2.2.1 随机过采样
&emsp;&emsp;随机欠采样是指多次随机从少数类样本中有放回的抽取数据，采样数量大于原有的少数类样本数量，其中有一部分数据会出现重复，而重复数据的出现会增大方差造成模型的过拟合。
### 2.2.2 SMOTE算法
&emsp;&emsp;SMOTE全称是Synthetic Minority Oversampling Technique即合成少数类过采样技术，它是基于随机过采样算法的一种改进方案，SMOTE算法的基本思想是对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中。
&emsp;&emsp;SMOTE 算法是利用特征空间中现存少数类样本之间的相似性来建立人工数据的，也可以认为SMOTE算法假设了在相距较近的少数类样本之间的样本仍然是少数类，具体过程如下：
- 随机选择一个少数类样本，计算它到少数类样本集中所有样本的距离，得到它k近邻;
- 根据样本不平衡比例设置一个采样比例以确定采样倍率n，对于每一个少数类样本x，从其k近邻中随机选择若干个样本;
- 对于每一个随机选出的近邻，选择一个在[0,1]之间的随机数乘以随机近邻和x的特征向量的差，然后加上一个x,用公式表示：
$$
x_{new}=x+rand(0,1)\times(\hat{x}-x)
$$

&emsp;&emsp;SMOTE算法摒弃了随机过采样复制样本的做法，可以防止随机过采样易过拟合的问题，而这些多出来的样本本身不带有信息，而且SMOTE 算法对于每个原少数类样本产生相同数量的合成数据样本，这就使得类间发生重复的可能性加大。

### 2.2.3 Borderline-SMOTE算法
&emsp;&emsp;Borderline-SMOTE算法较SMOTE算法提升的地方是只为那些K近邻中有一半以上多数类样本的少数类样本生成新样本，因为这些样本容易被错分，而在这些少数类样本附近生存人工合成样本，有助于少数类样本的分类正确。而如果少数类样本周围全是多数类样本，这种情况下，这个样本会被认定为噪声样本。
&emsp;&emsp;Borderline-SMOTE算法筛选样本的公式如下：
$$
\frac{k}{2}<|S_{i-knn}∩S_{maj}|<k
$$
&emsp;&emsp;它的选择过程如下：
- 对于每个 $x_i⊂S_{min}$确定一系列最近邻样本集，称该数据集为$S_{i-knn}，且$S_{i-knn}⊂S$;
- 对每个样本$x_i$，判断出最近邻样本集中属于多数类样本的个数，即：$|S_{i-knn}⋂S_{maj}|$;
- 选择满足上面不等式的$x_i$。

### 2.2.4 基于k-means过采样
&emsp;&emsp;基于k-means聚类过采样方法一般分为两步：
- 首先分别对正负例进行K-means聚类;
- 聚类之后，对其中较小的簇进行上面的过采样方法扩充样本数量;
- 然后在进行正负类样本均衡扩充。

&emsp;&emsp;该算法不仅可以解决类间不平衡问题，而且还能解决类内部不平衡问题。

## 2.3 分类阈值移动
&emsp;&emsp;根据样本量修改分类阈值。

# 3 参考
[机器学习中的类别不均衡问题
](https://www.cnblogs.com/wkslearner/p/8870673.html)